# Attention Mechanismen f√ºr multivariate Zeitreihen -
# Interpretierbare Sensorik-Analysen bei Sensordrift

Dieses Projekt untersucht die Klassifikation von Gasarten (1‚Äì6) anhand multivariater Sensordaten unter Ber√ºcksichtigung von Sensordrift.
Neben der reinen Vorhersageleistung liegt ein starker Fokus auf Interpretierbarkeit mittels Attention-Mechanismen und Feature-Analysen.


# Motivation & Problemstellung

In realen Sensorsystemen (z. B. industrielle Gasdetektion) treten zwei zentrale Herausforderungen auf:

1. Multivariate Zeitreihen
   ‚Üí Viele Sensoren liefern gleichzeitig Messwerte, die zeitlich voneinander abh√§ngen.
2- Sensordrift
    ‚Üí Sensoren ver√§ndern ihr Verhalten √ºber die Zeit (Alterung, Umweltbedingungen),
    wodurch sich Datenverteilungen verschieben und Modelle an Genauigkeit verlieren.

Ziel:
Robuste Klassifikation der Gasarten und gleichzeitige Erkl√§rbarkeit, um zu verstehen:

- welche Sensoren
- zu welchen Zeitpunkten
- unter Driftbedingungen

entscheidend f√ºr die Modellentscheidung sind.


 # Datensatz

- UCI Gas Sensor Array Drift Dataset
- Multivariate Zeitreihen von Gassensoren
- Labels: 6 verschiedene Gasarten
- Enth√§lt explizit zeitabh√§ngige Drift-Effekte


# Ziele des Projekts

- Klassifikation der Gasarten (1‚Äì6)
- Vergleich klassischer ML-Modelle mit Deep-Learning-Ans√§tzen
- Analyse der Auswirkungen von Sensordrift
- Interpretierbarkeit durch Feature Importance & Attention Scores
- Saubere, modulare und reproduzierbare ML-Pipeline


# Modellarchitektur & Baselines
# Klassische ML-Baseline

Random Forest
  - Trainiert auf aggregierten Features
  - Nach Training:
     - Konfusionsmatrix
     - Feature Importance Analyse
   
LSTM und Transformer
   - Sequenzbasierte Inputs
   - Modellierung zeitlicher Abh√§ngigkeiten
   - Attention-Scores zur Gewichtung wichtiger Zeitpunkte
   - Driftanalyse zur Identifikation des Zeitpunkts modellinterner Wahrnehmung des Drifts (mit Schwellenwert)
   - Nach Training:
        - Erstellung von Sequenzen
        - Visualisierung von Train/Test-Loss
        - Anzeige der ersten N Klassifikationen auf Testdaten
        - Analyse & Visualisierung der Attention Scores
        - Driftanalyse anhand von Hidden States und Attention-Gewichten
    

# Training & Evaluation

- Alle 3 Modelle wurden vollst√§ndig trainiert
- 5-Fold Cross-Validation zur stabilen Evaluation
- Grid Search f√ºr Hyperparameter-Optimierung der neuronalen Modelle
- Vergleich der Modelle anhand:
   - Accuracy
   - Konfusionsmatrix
   - Robustheit gegen√ºber Drift
   - Interpretierbarkeit
 


# Interpretierbarkeit

- Random Forest:
   - Feature Importance zur Identifikation relevanter Sensoren

- LSTM & Transformer:
  - Attention Scores zur Analyse:
  - Welche Zeitpunkte entscheidend sind
  - Welche Sensoren unter Drift besonders gewichtet werden
  - Zusammenhang zwischen Drift und Modellfokus
 

# Technologien & Tools

- Python
- NumPy, Pandas, Scikit-Learn
- PyTorch 
- Matplotlib, Seaborn
- Jupyter Notebook
- Modularer Projektaufbau



# Modell√ºbersicht & Ergebnisse

Ziel:
Klassifikation von Gasarten aus multivariaten Zeitreihen unter Sensordrift mit Fokus auf Interpretierbarkeit.

# Gemeinsames Setup

- Datensatz: UCI Gas Sensor Array Drift Dataset
- Train/Test Split: 80 % / 20 %
- Evaluation: 5-Fold Cross-Validation
- Hauptmetrik: Accuracy
- Zus√§tzliche Analyse:
     - Attention Scores
     - Hidden-State-Driftanalyse


üå≤ Random Forest

- Accuracy: 99,53 % (h√∂chste)
- Sehr geringer Trainingsaufwand
- Feature Importance zur globalen Interpretierbarkeit
- Limitationen:
   - Keine Sequenzmodellierung
   - Keine zeitabh√§ngige Interpretierbarkeit
   - Keine Attention-Mechanismen

-> Stark f√ºr effiziente Klassifikation, eingeschr√§nkt f√ºr Drift- und Zeitreihenanalyse



üîÅ LSTM + Attention

- Accuracy: 97,29 %
- Sehr gut geeignet f√ºr zeitliche Abh√§ngigkeiten
- Attention Scores zeigen relevante Zeitpunkte innerhalb der Sequenz
- Hidden-State-Analyse erh√∂ht Interpretierbarkeit
- Keine Drift-Warnungen erkannt
- Trainingsaufwand: mittel

-> Gute Balance zwischen Performance und zeitlicher Interpretierbarkeit



üîÄ Transformer + Self-Attention

- Accuracy: 98,54 %
- Robuste Modellierung komplexer Sequenzen
- Self-Attention reagiert sensitiv auf Ver√§nderungen in Zeitreihen
- Attention Scores + Hidden-State-Analyse
- Mehrere Drift-Warnungen erkannt
- Trainingsaufwand: mittel

-> H√∂chste Interpretierbarkeit und beste Drift-Sensitivit√§t



# Fazit

- Alle Modelle sind f√ºr die Gasklassifikation geeignet
- Random Forest: effizient & sehr genau
- LSTM & Transformer: klare Vorteile bei zeitlicher Modellierung und Erkl√§rbarkeit
- Transformer: besonders geeignet f√ºr driftkritische und sicherheitsrelevante Anwendungen
